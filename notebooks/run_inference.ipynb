{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "run_inference.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumik12345/point-cloud-segmentation/blob/main/notebooks/run_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Po1n4ADRmSZ"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZklFv5pRW1D"
      },
      "source": [
        "!git clone https://github.com/soumik12345/point-cloud-segmentation -q\n",
        "!pip install wandb ml_collections -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BylQNdDyRhva"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"point-cloud-segmentation\")\n",
        "\n",
        "from point_seg import transform_block\n",
        "from point_seg import ShapeNetCoreLoaderInMemory\n",
        "from configs import shapenetcore\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xl3VIeIRu8C"
      },
      "source": [
        "## Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iqsHm7jRtCZ"
      },
      "source": [
        "CATEGORY_TO_MODEL = {\n",
        "    \"airplane\": \"https://github.com/soumik12345/point-cloud-segmentation/releases/download/v0.3/airplane.gz\",\n",
        "    \"car\": \"https://github.com/soumik12345/point-cloud-segmentation/releases/download/v0.3/car.gz\",\n",
        "    \"chair\": \"https://github.com/soumik12345/point-cloud-segmentation/releases/download/v0.3/chair.tar.gz\",\n",
        "    \"table\": \"https://github.com/soumik12345/point-cloud-segmentation/releases/download/v0.3/table.tar.gz\",\n",
        "}\n",
        "\n",
        "\n",
        "CATEGORY = \"Table\"  #@param [\"Airplane\", \"Table\", \"Car\", \"Chair\"] {type:\"string\"}\n",
        "MODEL_URL = CATEGORY_TO_MODEL[CATEGORY.lower()]\n",
        "CONFIGS = shapenetcore.get_config()\n",
        "METADATA_URL = \"https://github.com/soumik12345/point-cloud-segmentation/releases/download/v0.2/metadata.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WpcFMfDTEiQ"
      },
      "source": [
        "## Load metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCj-y_yCSQhB"
      },
      "source": [
        "metadata_path = tf.keras.utils.get_file(\n",
        "    origin=METADATA_URL, fname=METADATA_URL.split(\"/\")[-1]\n",
        ")\n",
        "model_path = tf.keras.utils.get_file(\n",
        "    origin=MODEL_URL, fname=MODEL_URL.split(\"/\")[-1], untar=True\n",
        ")\n",
        "\n",
        "with open(metadata_path) as json_file:\n",
        "    metadata = json.load(json_file)\n",
        "\n",
        "LABELS = metadata[CATEGORY][\"lables\"]\n",
        "COLORS = metadata[CATEGORY][\"colors\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOAIq4kfTIDB"
      },
      "source": [
        "## Visualization utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjgAYtTjS17R"
      },
      "source": [
        "def visualize_data(point_cloud, labels):\n",
        "    fig = px.scatter_3d(\n",
        "        pd.DataFrame(\n",
        "            data={\n",
        "                \"x\": point_cloud[:, 0],\n",
        "                \"y\": point_cloud[:, 1],\n",
        "                \"z\": point_cloud[:, 2],\n",
        "                \"label\": labels,\n",
        "            }\n",
        "        ),\n",
        "        x=\"x\",\n",
        "        y=\"y\",\n",
        "        z=\"z\",\n",
        "        color=\"label\",\n",
        "        labels={\"label\": \"Label\"},\n",
        "        color_discrete_sequence=COLORS,\n",
        "        category_orders={\"label\": LABELS},\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def visualize_single_point_cloud(point_clouds, label_clouds, idx):\n",
        "    label_map = LABELS + [\"none\"]\n",
        "    point_cloud = point_clouds[idx]\n",
        "    label_cloud = label_clouds[idx]\n",
        "    visualize_data(point_cloud, [label_map[np.argmax(label)] for label in label_cloud])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7U3Z9NfTOGX"
      },
      "source": [
        "data_loader = ShapeNetCoreLoaderInMemory(\n",
        "    object_category=CATEGORY, n_sampled_points=CONFIGS.num_points,\n",
        ")\n",
        "data_loader.load_data()\n",
        "_, val_dataset = data_loader.get_datasets(\n",
        "    val_split=CONFIGS.val_split, batch_size=CONFIGS.batch_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujOyB1CgTpq_"
      },
      "source": [
        "## Load model for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDv_eJzTffS"
      },
      "source": [
        "segmentation_model = tf.keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\"OrthogonalRegularizer\": transform_block.OrthogonalRegularizer},\n",
        ")\n",
        "val_data_batch = next(iter(val_dataset))\n",
        "val_predictions = segmentation_model.predict(val_data_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2ZoRIHqaRts"
      },
      "source": [
        "idx = np.random.choice(len(val_data_batch[0]))\n",
        "print(f\"Index selected: {idx}\")\n",
        "\n",
        "# Plotting with ground-truth.\n",
        "print(\"***********Ground-truth***********\")\n",
        "visualize_single_point_cloud(val_data_batch[0], val_data_batch[1], idx)\n",
        "\n",
        "# Plotting with predicted labels.\n",
        "print(\"***********Predicted***********\")\n",
        "visualize_single_point_cloud(val_data_batch[0], val_predictions, idx)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}