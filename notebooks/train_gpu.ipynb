{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLQKeIsE1JaWZTWPGDKJN4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumik12345/point-cloud-segmentation/blob/inference/notebooks/train_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUyfFIyFnnSU",
        "outputId": "f0340674-2a44-4aaf-bef5-f4fc3b33afbb"
      },
      "source": [
        "!git clone https://github.com/soumik12345/point-cloud-segmentation\n",
        "!pip install -qqq wandb ml_collections"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'point-cloud-segmentation'...\n",
            "remote: Enumerating objects: 734, done.\u001b[K\n",
            "remote: Counting objects: 100% (734/734), done.\u001b[K\n",
            "remote: Compressing objects: 100% (460/460), done.\u001b[K\n",
            "remote: Total 734 (delta 430), reused 487 (delta 228), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (734/734), 2.99 MiB | 8.94 MiB/s, done.\n",
            "Resolving deltas: 100% (430/430), done.\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 88 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 180 kB 89.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 139 kB 81.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORynKakaoCai"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"point-cloud-segmentation\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKP1ealyoFTR"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D_Xj7TcoJQx"
      },
      "source": [
        "import os\n",
        "\n",
        "import wandb\n",
        "import wandb.keras\n",
        "from datetime import datetime\n",
        "\n",
        "from tensorflow.keras import optimizers, callbacks\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "from point_seg import TFRecordLoader, ShapeNetCoreLoaderInMemory\n",
        "from point_seg import models, utils"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJrMXulMoPMZ"
      },
      "source": [
        "#@title Configs\n",
        "#@markdown Get your `wandb_api_key` from https://wandb.ai/authorize.\n",
        "wandb_api_key = \"\" #@param {type:\"string\"}\n",
        "object_category = \"Bag\" #@param {type:\"string\"}\n",
        "num_points = 1024 #@param {type:\"integer\"}\n",
        "batch_size = 32 #@param {type:\"integer\"}\n",
        "val_split = 0.2 #@param {type:\"number\"}\n",
        "epochs = 60 #@param {type:\"integer\"}\n",
        "initial_lr = 1e-3 #@param {type:\"number\"}\n",
        "drop_every = 10 #@param {type:\"integer\"}\n",
        "decay_factor = 0.5 #@param {type:\"number\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmAl_DajocRK"
      },
      "source": [
        "timestamp = datetime.utcnow().strftime(\"%y%m%d-%H%M%S\")\n",
        "strategy = utils.initialize_device()\n",
        "batch_size = 32 * strategy.num_replicas_in_sync"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "GWCLRRPiohwh",
        "outputId": "fef642fb-a295-486f-e23a-17b2ca44fbe0"
      },
      "source": [
        "wandb.init(\n",
        "    project='pointnet_shapenet_core',\n",
        "    name=f\"{object_category}_{timestamp}\",\n",
        "    entity=\"pointnet\",\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpointnet\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/pointnet/pointnet_shapenet_core/runs/2rp2ydue\" target=\"_blank\">Bag_211030-062642</a></strong> to <a href=\"https://wandb.ai/pointnet/pointnet_shapenet_core\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f96b0183250>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pointnet/pointnet_shapenet_core/runs/2rp2ydue?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXs5a1gZooFZ",
        "outputId": "b360a90d-4fc1-48d1-d71c-7f8f3d15c6ab"
      },
      "source": [
        "# Apply mixed-precision policy [OPTIONAL]\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "policy = mixed_precision.global_policy()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla P100-PCIE-16GB, compute capability 6.0\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ENDo5jovzS",
        "outputId": "d10d8802-b6ed-4a4a-a87d-006d7d78e85c"
      },
      "source": [
        "data_loader = ShapeNetCoreLoaderInMemory(\n",
        "    object_category=object_category,\n",
        "    n_sampled_points=num_points,\n",
        ")\n",
        "data_loader.load_data()\n",
        "train_dataset, val_dataset = data_loader.get_datasets(\n",
        "    val_split=val_split,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 83/83 [00:03<00:00, 22.33it/s]\n",
            "100%|██████████| 79/79 [00:00<00:00, 395.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCRAcznEo0Ph"
      },
      "source": [
        "lr_scheduler = utils.StepDecay(initial_lr, drop_every, decay_factor)\n",
        "lr_callback = callbacks.LearningRateScheduler(\n",
        "    lambda epoch: lr_scheduler(epoch), verbose=True\n",
        ")\n",
        "\n",
        "# Tensorboard Callback\n",
        "logs_dir = os.path.join(\n",
        "    \"logs\", f\"{object_category}_{timestamp}\"\n",
        ")\n",
        "logs_dir = os.path.join(logs_dir)\n",
        "tb_callback = callbacks.TensorBoard(log_dir=logs_dir)\n",
        "\n",
        "# ModelCheckpoint Callback\n",
        "checkpoint_path = os.path.join(\n",
        "    \"training_checkpoints\",\n",
        "    f\"{object_category}_{timestamp}.h5\",\n",
        ")\n",
        "checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, save_best_only=True, save_weights_only=True,\n",
        ")\n",
        "\n",
        "callback_list = [\n",
        "    tb_callback,\n",
        "    checkpoint_callback,\n",
        "    lr_callback,\n",
        "    wandb.keras.WandbCallback()\n",
        "]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyUqjCCSrN0t"
      },
      "source": [
        "with strategy.scope():\n",
        "    optimizer = optimizers.Adam(learning_rate=initial_lr)\n",
        "    _, y = next(iter(train_dataset))\n",
        "    num_classes = y.shape[-1]\n",
        "    model = models.get_shape_segmentation_model(num_points, num_classes)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1yuwJxerRqe",
        "outputId": "0758a6ff-0eeb-4ced-ccd9-30a1d8784c52"
      },
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=callback_list,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 8s 2s/step - loss: 12.9136 - accuracy: 0.1329 - val_loss: 82.6287 - val_accuracy: 0.0618\n",
            "Epoch 2/60\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 290ms/step - loss: 10.7233 - accuracy: 0.2365 - val_loss: 60.4566 - val_accuracy: 0.0065\n",
            "Epoch 3/60\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 299ms/step - loss: 8.0717 - accuracy: 0.3747 - val_loss: 9.0782 - val_accuracy: 0.1403\n",
            "Epoch 4/60\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 282ms/step - loss: 6.8129 - accuracy: 0.4994 - val_loss: 5.3153 - val_accuracy: 0.5540\n",
            "Epoch 5/60\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 5.8839 - accuracy: 0.6959 - val_loss: 8.2324 - val_accuracy: 0.6024\n",
            "Epoch 6/60\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 293ms/step - loss: 5.4746 - accuracy: 0.8179 - val_loss: 3.1758 - val_accuracy: 0.9539\n",
            "Epoch 7/60\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 288ms/step - loss: 5.3147 - accuracy: 0.8266 - val_loss: 2.9856 - val_accuracy: 0.8822\n",
            "Epoch 8/60\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 5.1078 - accuracy: 0.9166 - val_loss: 2.8728 - val_accuracy: 0.9183\n",
            "Epoch 9/60\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.001.\n",
            "2/2 [==============================] - 0s 284ms/step - loss: 4.7392 - accuracy: 0.9477 - val_loss: 2.8200 - val_accuracy: 0.9093\n",
            "Epoch 10/60\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 4.6826 - accuracy: 0.9436 - val_loss: 2.5917 - val_accuracy: 0.9373\n",
            "Epoch 11/60\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.6348 - accuracy: 0.9527 - val_loss: 2.5492 - val_accuracy: 0.9598\n",
            "Epoch 12/60\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.4685 - accuracy: 0.9568 - val_loss: 2.4475 - val_accuracy: 0.9501\n",
            "Epoch 13/60\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.4639 - accuracy: 0.9524 - val_loss: 2.3920 - val_accuracy: 0.9565\n",
            "Epoch 14/60\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.4138 - accuracy: 0.9575 - val_loss: 2.5367 - val_accuracy: 0.8809\n",
            "Epoch 15/60\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 297ms/step - loss: 4.3748 - accuracy: 0.9580 - val_loss: 2.5021 - val_accuracy: 0.9533\n",
            "Epoch 16/60\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 293ms/step - loss: 4.3450 - accuracy: 0.9549 - val_loss: 2.3719 - val_accuracy: 0.9576\n",
            "Epoch 17/60\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 4.3396 - accuracy: 0.9586 - val_loss: 2.3512 - val_accuracy: 0.9598\n",
            "Epoch 18/60\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.3286 - accuracy: 0.9539 - val_loss: 2.4326 - val_accuracy: 0.9092\n",
            "Epoch 19/60\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0005.\n",
            "2/2 [==============================] - 0s 287ms/step - loss: 4.3122 - accuracy: 0.9595 - val_loss: 3.1602 - val_accuracy: 0.9025\n",
            "Epoch 20/60\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 297ms/step - loss: 4.2875 - accuracy: 0.9629 - val_loss: 2.2995 - val_accuracy: 0.9608\n",
            "Epoch 21/60\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 4.2818 - accuracy: 0.9600 - val_loss: 2.2854 - val_accuracy: 0.9628\n",
            "Epoch 22/60\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.2870 - accuracy: 0.9642 - val_loss: 2.2840 - val_accuracy: 0.9600\n",
            "Epoch 23/60\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 287ms/step - loss: 4.2586 - accuracy: 0.9629 - val_loss: 2.3093 - val_accuracy: 0.9599\n",
            "Epoch 24/60\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.2815 - accuracy: 0.9640 - val_loss: 2.3112 - val_accuracy: 0.9614\n",
            "Epoch 25/60\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 288ms/step - loss: 4.2592 - accuracy: 0.9650 - val_loss: 2.2858 - val_accuracy: 0.9611\n",
            "Epoch 26/60\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 4.2401 - accuracy: 0.9648 - val_loss: 2.2715 - val_accuracy: 0.9601\n",
            "Epoch 27/60\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 291ms/step - loss: 4.2669 - accuracy: 0.9661 - val_loss: 5.3277 - val_accuracy: 0.8358\n",
            "Epoch 28/60\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.2387 - accuracy: 0.9679 - val_loss: 2.3081 - val_accuracy: 0.9562\n",
            "Epoch 29/60\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.00025.\n",
            "2/2 [==============================] - 0s 284ms/step - loss: 4.2426 - accuracy: 0.9660 - val_loss: 2.2800 - val_accuracy: 0.9591\n",
            "Epoch 30/60\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 4.2336 - accuracy: 0.9679 - val_loss: 2.3045 - val_accuracy: 0.9533\n",
            "Epoch 31/60\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 303ms/step - loss: 4.2257 - accuracy: 0.9682 - val_loss: 2.3477 - val_accuracy: 0.9453\n",
            "Epoch 32/60\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 290ms/step - loss: 4.2327 - accuracy: 0.9676 - val_loss: 3.4049 - val_accuracy: 0.8415\n",
            "Epoch 33/60\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 295ms/step - loss: 4.2371 - accuracy: 0.9665 - val_loss: 2.2901 - val_accuracy: 0.9639\n",
            "Epoch 34/60\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 290ms/step - loss: 4.2140 - accuracy: 0.9689 - val_loss: 2.2646 - val_accuracy: 0.9635\n",
            "Epoch 35/60\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.2201 - accuracy: 0.9697 - val_loss: 2.2604 - val_accuracy: 0.9598\n",
            "Epoch 36/60\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 287ms/step - loss: 4.2106 - accuracy: 0.9702 - val_loss: 2.2520 - val_accuracy: 0.9631\n",
            "Epoch 37/60\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 293ms/step - loss: 4.2141 - accuracy: 0.9699 - val_loss: 2.3243 - val_accuracy: 0.9430\n",
            "Epoch 38/60\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 294ms/step - loss: 4.2168 - accuracy: 0.9685 - val_loss: 2.6124 - val_accuracy: 0.8823\n",
            "Epoch 39/60\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000125.\n",
            "2/2 [==============================] - 0s 294ms/step - loss: 4.2180 - accuracy: 0.9700 - val_loss: 2.2549 - val_accuracy: 0.9602\n",
            "Epoch 40/60\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 282ms/step - loss: 4.1962 - accuracy: 0.9715 - val_loss: 2.2417 - val_accuracy: 0.9622\n",
            "Epoch 41/60\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 298ms/step - loss: 4.2048 - accuracy: 0.9710 - val_loss: 2.2385 - val_accuracy: 0.9606\n",
            "Epoch 42/60\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 290ms/step - loss: 4.2497 - accuracy: 0.9659 - val_loss: 2.2698 - val_accuracy: 0.9634\n",
            "Epoch 43/60\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 297ms/step - loss: 4.2119 - accuracy: 0.9681 - val_loss: 2.2604 - val_accuracy: 0.9591\n",
            "Epoch 44/60\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.2210 - accuracy: 0.9699 - val_loss: 2.2488 - val_accuracy: 0.9646\n",
            "Epoch 45/60\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 288ms/step - loss: 4.2142 - accuracy: 0.9700 - val_loss: 2.2648 - val_accuracy: 0.9603\n",
            "Epoch 46/60\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 290ms/step - loss: 4.1956 - accuracy: 0.9721 - val_loss: 2.2423 - val_accuracy: 0.9660\n",
            "Epoch 47/60\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 284ms/step - loss: 4.1989 - accuracy: 0.9714 - val_loss: 2.2420 - val_accuracy: 0.9647\n",
            "Epoch 48/60\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 287ms/step - loss: 4.1991 - accuracy: 0.9707 - val_loss: 2.2489 - val_accuracy: 0.9638\n",
            "Epoch 49/60\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 6.25e-05.\n",
            "2/2 [==============================] - 0s 301ms/step - loss: 4.1965 - accuracy: 0.9702 - val_loss: 2.2486 - val_accuracy: 0.9642\n",
            "Epoch 50/60\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.2024 - accuracy: 0.9719 - val_loss: 2.2590 - val_accuracy: 0.9617\n",
            "Epoch 51/60\n",
            "\n",
            "Epoch 00051: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 4.1943 - accuracy: 0.9727 - val_loss: 2.2502 - val_accuracy: 0.9584\n",
            "Epoch 52/60\n",
            "\n",
            "Epoch 00052: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 294ms/step - loss: 4.2088 - accuracy: 0.9701 - val_loss: 2.2554 - val_accuracy: 0.9592\n",
            "Epoch 53/60\n",
            "\n",
            "Epoch 00053: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 288ms/step - loss: 4.2029 - accuracy: 0.9714 - val_loss: 2.8267 - val_accuracy: 0.8911\n",
            "Epoch 54/60\n",
            "\n",
            "Epoch 00054: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 286ms/step - loss: 4.1963 - accuracy: 0.9732 - val_loss: 2.2356 - val_accuracy: 0.9645\n",
            "Epoch 55/60\n",
            "\n",
            "Epoch 00055: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 285ms/step - loss: 4.1958 - accuracy: 0.9723 - val_loss: 2.2737 - val_accuracy: 0.9613\n",
            "Epoch 56/60\n",
            "\n",
            "Epoch 00056: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 4.2038 - accuracy: 0.9697 - val_loss: 2.2480 - val_accuracy: 0.9624\n",
            "Epoch 57/60\n",
            "\n",
            "Epoch 00057: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 292ms/step - loss: 4.2007 - accuracy: 0.9715 - val_loss: 2.2394 - val_accuracy: 0.9645\n",
            "Epoch 58/60\n",
            "\n",
            "Epoch 00058: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 291ms/step - loss: 4.2102 - accuracy: 0.9733 - val_loss: 2.2466 - val_accuracy: 0.9617\n",
            "Epoch 59/60\n",
            "\n",
            "Epoch 00059: LearningRateScheduler setting learning rate to 3.125e-05.\n",
            "2/2 [==============================] - 0s 283ms/step - loss: 4.2020 - accuracy: 0.9706 - val_loss: 2.2481 - val_accuracy: 0.9640\n",
            "Epoch 60/60\n",
            "\n",
            "Epoch 00060: LearningRateScheduler setting learning rate to 1.5625e-05.\n",
            "2/2 [==============================] - 0s 299ms/step - loss: 4.1887 - accuracy: 0.9723 - val_loss: 2.2440 - val_accuracy: 0.9653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9627eaa3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZHy_6cZswi1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}